{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8592b10-f936-4bc2-9250-6131c8802306",
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4 as nc\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a73128-883f-471f-a4f8-aedeff307f80",
   "metadata": {},
   "source": [
    "#download\n",
    "!curl https://zenodo.org/record/6532501/files/CESM_EA_SPI.nc?download=1 --output CESM_EA_SPI.nc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177ab34f-0ff7-442e-a896-9f8477f0ca83",
   "metadata": {},
   "source": [
    "# Run Main file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178c4365-279a-4b83-a847-9e070a24e6e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%run train_siren.py --fast_dev_run 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf8b527-f25b-4ae8-b54f-890e16dbc764",
   "metadata": {},
   "source": [
    "## RAW DATA SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c29276a-8218-4149-962f-ef230d431dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'CESM_EA_SPI.nc'\n",
    "ds = xr.open_dataset(file_name)\n",
    "spi = ds['spi']\n",
    "ds.close()\n",
    "spi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed3073d-1cff-43ae-be48-dc8554c15c3d",
   "metadata": {},
   "source": [
    "# Experiment month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dab5e7f-6182-426c-9606-b4085278ef4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_month = pd.DataFrame(spi[\"time\"].to_series().values, columns=['time'])\n",
    "month = dim_month['time'].apply(lambda x: datetime.strptime(str(x), '%Y-%m-%dT%H:%M:%S').month).values\n",
    "fract = (month-1)/12*np.pi*2\n",
    "month_sin = np.sin(fract)\n",
    "month_cos = np.cos(fract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dda37d-2e65-4e27-bb24-84a089411fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2e41d5-ea31-4bc8-9b6e-ca66559cd681",
   "metadata": {},
   "outputs": [],
   "source": [
    "month = 12\n",
    "tmp=(month-1)/12*np.pi*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c409ea-20c2-4a9f-808e-be4fc5ece809",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sin(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e5e0e1-77ad-4e39-9795-185c4f9e16a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.cos(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17c1dd3-4c96-409a-bb82-e5fcebc342b0",
   "metadata": {},
   "source": [
    "# Experiment Padding Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d52bc7-2d83-47d8-aa29-ff8812049c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = train_predictands[0,:,:]\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a23a31-9b15-451c-ab82-e3ac78de2128",
   "metadata": {},
   "outputs": [],
   "source": [
    "window=1\n",
    "img_pad = np.pad(img, pad_width=window, mode='symmetric')\n",
    "img_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b39671-d58e-4fb9-bd56-a7278cb3c068",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.reshape(np.shape(X)[0]*np.shape(X)[1]*np.shape(X)[2], np.shape(X)[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb8c153-7931-4037-bef3-98b703ddf723",
   "metadata": {},
   "outputs": [],
   "source": [
    "window=5\n",
    "\n",
    "data_x = []\n",
    "data_y = []\n",
    "\n",
    "for time_idx in range(num_samples):\n",
    "    img_y = y[time_idx,:,:]\n",
    "    img_pad_y = np.pad(img_y, pad_width=window, mode='symmetric')\n",
    "    \n",
    "    img_x = X[time_idx,:,:,:]\n",
    "    img_pad_x[:,:,0] = np.pad(img_pad_y[:,:,0], pad_width=window, mode='symmetric')\n",
    "    img_pad_x[:,:,1] = np.pad(img_pad_y[:,:,1], pad_width=window, mode='symmetric')\n",
    "    img_pad_x[:,:,2] = np.pad(img_pad_y[:,:,2], pad_width=window, mode='symmetric')\n",
    "    \n",
    "    for lat in range(window, 13):\n",
    "        for lon in range(window, 20):\n",
    "            # y\n",
    "            sample_y = img_pad_y[lat:lat+window,lon:lon+window]\n",
    "            sample_y = sample_y.reshape(np.shape(sample_y)[0]*np.shape(sample_y)[1])\n",
    "            data_y.append(sample_y)\n",
    "            \n",
    "            # x\n",
    "            sample = img_pad_x[lat:lat+window,lon:lon+window,:]\n",
    "            sample = sample.reshape(np.shape(sample)[0]*np.shape(sample)[1]*np.shape(sample)[2])\n",
    "            data_x.append(sample)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77dee9a-adc9-4540-981f-c8ef711ee6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "spi[dict(time=0, lat=slice(None, 2), lon=slice(None, 2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8719cc-ac80-4bf7-8133-9664e0c366ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "spi.sel(lat=slice(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0187129-02cc-4f16-bed0-8d4f46e3a37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot spatial spi distribution for random time\n",
    "time = np.random.randint(spi.shape[0])\n",
    "spi2d = spi.isel(time=time)\n",
    "spi2d.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711a36f4-8f42-464b-8d59-3286adcf2305",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot spi time series at random location\n",
    "lat = np.random.randint(spi.shape[1])\n",
    "lon = np.random.randint(spi.shape[2])\n",
    "k = np.random.randint(spi.shape[0]-1000)\n",
    "plt.plot(spi[k:k+1000,lat,lon])\n",
    "plt.ylabel('SPI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2071b52-f150-4f02-9c41-a717bb9da816",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot overall spi distribution\n",
    "plt.hist(np.array(spi).flatten(), bins=100)\n",
    "plt.title('SPI distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd12f5c9-4034-4f7a-87f5-d31c03330283",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e07ff5-aa8a-4460-a41e-c2c1273b11fd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def helge_assemble_predictors_predictands(start_date, end_date, lead_time, dataset, num_input_time_steps, window=5):\n",
    "    '''\n",
    "    Args\n",
    "    ----\n",
    "    start_date (str): The start date for extraction. Important, put the trailing 0 at the beginning of year for dates before 1000 (e.g., '0400')\n",
    "    end_date (str): The end date for extraction\n",
    "    lead_time (int): The number of months between the predictor/predictand\n",
    "    dataset (str): Either 'CESM' or 'ECMWF'\n",
    "    num_input_time_steps (int): The number of time steps to use for each predictor samples\n",
    "    '''    \n",
    "    file_name = {'CESM': 'CESM_EA_SPI.nc', 'ECMWF': 'ECMWF_EA_SPI.nc'}[dataset]\n",
    "    ds = xr.open_dataset(file_name)\n",
    "    spi = ds['spi'].sel(time=slice(start_date,end_date))\n",
    "    num_samples=spi.shape[0] \n",
    "    #Stack and remove nans\n",
    "    spi = np.stack([spi.values[n-num_input_time_steps:n] for n in range(num_input_time_steps, num_samples+1)])\n",
    "    num_samples = spi.shape[0]\n",
    "    spi[np.isnan(spi)] = 0\n",
    "    #make sure we have floats in there\n",
    "    X = spi.astype(np.float32)\n",
    "    # select Y\n",
    "    if dataset == 'ECMWF':\n",
    "        start_date_plus_lead = pd.to_datetime(start_date) + pd.DateOffset(months=lead_time+num_input_time_steps-1)\n",
    "        end_date_plus_lead = pd.to_datetime(end_date) + pd.DateOffset(months=lead_time)\n",
    "    elif dataset == 'CESM':\n",
    "        t_start=datetime.datetime(int(start_date.split('-')[0]),int(start_date.split('-')[1]),int(start_date.split('-')[2]))\n",
    "        t_end=datetime.datetime(int(end_date.split('-')[0]),int(end_date.split('-')[1]),int(end_date.split('-')[2]))\n",
    "        start_date_plus_lead = t_start + relativedelta(months=lead_time+num_input_time_steps-1)\n",
    "        end_date_plus_lead = t_end + relativedelta(months=lead_time)\n",
    "        if len(str(start_date_plus_lead.year))<4:\n",
    "            start_date_plus_lead = '0'+start_date_plus_lead.strftime('%Y-%m-%d')\n",
    "        elif len(str(start_date_plus_lead.year))==4:\n",
    "            start_date_plus_lead = start_date_plus_lead.strftime('%Y-%m-%d')\n",
    "        if len(str(end_date_plus_lead.year))<4:\n",
    "            end_date_plus_lead = '0'+end_date_plus_lead.strftime('%Y-%m-%d')\n",
    "        elif len(str(end_date_plus_lead.year))==4:\n",
    "            end_date_plus_lead = end_date_plus_lead.strftime('%Y-%m-%d')\n",
    "    subsetted_ds = ds['spi'].sel(time=slice(start_date_plus_lead, end_date_plus_lead))\n",
    "    y = subsetted_ds.values.astype(np.float32)\n",
    "    y[np.isnan(y)] = 0\n",
    "    # add month feature\n",
    "    month = pd.DataFrame(subsetted_ds[\"time\"].to_series().values, columns=['time'])\n",
    "    month = month['time'].apply(lambda x: datetime.datetime.strptime(str(x), '%Y-%m-%dT%H:%M:%S').month).values\n",
    "    fract = (month-1)/12*np.pi*2\n",
    "    month_sin = np.sin(fract)\n",
    "    month_cos = np.cos(fract)       \n",
    "    ds.close()\n",
    "    X = np.moveaxis(X, 1,3)\n",
    "    orig_shape_X = X.shape\n",
    "    orig_shape_y = y.shape\n",
    "    #y = y.reshape(np.shape(y)[0]*np.shape(y)[1]*np.shape(y)[2])\n",
    "    #X = X.reshape(np.shape(X)[0]*np.shape(X)[1]*np.shape(X)[2], np.shape(X)[3])\n",
    "\n",
    "    data_set = []\n",
    "    halfwindow = int(window/2)\n",
    "\n",
    "    for time_idx in range(num_samples):\n",
    "        img_y = y[time_idx,:,:]\n",
    "        img_pad_y = np.pad(img_y, pad_width=window, mode='symmetric')\n",
    "        \n",
    "        img_x = X[time_idx,:,:,:]\n",
    "        img_pad_x = np.ndarray((img_pad_y.shape[0], img_pad_y.shape[1], 3))\n",
    "        img_pad_x[:,:,0] = np.pad(img_x[:,:,0], pad_width=window, mode='symmetric')\n",
    "        img_pad_x[:,:,1] = np.pad(img_x[:,:,1], pad_width=window, mode='symmetric')\n",
    "        img_pad_x[:,:,2] = np.pad(img_x[:,:,2], pad_width=window, mode='symmetric')\n",
    "        for lat in range(window, 13+window):\n",
    "            for lon in range(window, 20+window):\n",
    "\n",
    "                # x\n",
    "                sample = img_pad_x[lat-halfwindow:lat+halfwindow+1,lon-halfwindow:lon+halfwindow+1,:]\n",
    "                sample = sample.reshape(np.shape(sample)[0]*np.shape(sample)[1]*np.shape(sample)[2])\n",
    "                sample = np.append(sample, month_sin[time_idx])\n",
    "                sample = np.append(sample, month_cos[time_idx])\n",
    "                sample = np.append(sample, lat)\n",
    "                sample = np.append(sample, lon)\n",
    "                \n",
    "                # y\n",
    "                sample_y = img_pad_y[lat,lon]\n",
    "                #sample_y = img_pad_y[lat:lat+window,lon:lon+window]\n",
    "                #sample_y = sample_y.reshape(np.shape(sample_y)[0]*np.shape(sample_y)[1])\n",
    "                #data_y.append(sample_y)                \n",
    "                sample = np.append(sample, sample_y)\n",
    "                data_set.append(sample)\n",
    "        #break\n",
    "    return np.array(data_set)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f655e89-fb1d-4d99-8ffd-600f435af5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_input_time_steps = 3 \n",
    "lead_time = 3\n",
    "window = 3\n",
    "ver=1\n",
    "\n",
    "climate_model = 'CESM'\n",
    "\n",
    "all_start_date = '0400-01-01'\n",
    "all_end_date = '2021-12-31'\n",
    "\n",
    "#train_start_date = '0400-01-01'\n",
    "#train_end_date = '1800-12-31'\n",
    "\n",
    "#test_start_date = '1801-01-01'\n",
    "#test_end_date = '1978-12-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d08e13d-abe7-4002-b63a-ecf778cda361",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88ba132-fc07-41fa-abf3-8c934e24f630",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9b565f-c19d-46cb-8372-f284855dae2f",
   "metadata": {},
   "source": [
    "# Store new dataset as netcdf files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194f14a6-b8b9-45a2-a3b2-c71bd8876214",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def store_data(data_set, fn: str)->None:\n",
    "    import xarray as xr\n",
    "    sample_ticks = np.arange(data_set.shape[0])\n",
    "    input_ticks = np.arange(data_set.shape[1])\n",
    "\n",
    "    xr_drought = xr.DataArray(data_set, \n",
    "                 coords=[sample_ticks, input_ticks], \n",
    "                 dims=[\"sample_dim\", \"input_dim\"],\n",
    "                 name=\"samples\",\n",
    "                 attrs={\"begin\":all_start_date,\n",
    "                        \"end\":all_end_date,\n",
    "                        \"climate_model\":climate_model, \n",
    "                        \"num_input_time_steps\":num_input_time_steps,\n",
    "                        \"lead_time\":lead_time,\n",
    "                        \"unit\":\"Standard Precipitation Index (SPI)\",\n",
    "                      })\n",
    "\n",
    "    xr_dataset = xr.merge( [xr_drought], compat='override' )\n",
    "    print(xr_dataset)\n",
    "\n",
    "    xr_dataset.to_netcdf(fn)\n",
    "    \n",
    "# set seed\n",
    "seed = 1\n",
    "train_fract = 0.8\n",
    "import pytorch_lightning as pl\n",
    "pl.seed_everything(seed)\n",
    "\n",
    "# split in train and test data\n",
    "import numpy as np\n",
    "rng = np.random.default_rng(seed)\n",
    "msk = rng.random(data_set.shape[0]) < 0.8\n",
    "data_set_train = data_set[msk,:]\n",
    "data_set_test = data_set[~msk,:]\n",
    "\n",
    "ver = 1\n",
    "fn = \"helge_TRAIN_dataset_window{}_sincostime_ver{}.nc\".format(window,ver)\n",
    "store_data(data_set_train, fn)\n",
    "\n",
    "fn = \"helge_TEST_dataset_window{}_sincostime_ver{}.nc\".format(window,ver)\n",
    "store_data(data_set_test, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce8eed1-9a74-4d6b-a53f-4fab4aada387",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa12fbaa-c485-4323-bb2d-cd7f9f02c3e0",
   "metadata": {},
   "source": [
    "# Store mean std dev of training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9d13f9-b626-46b9-aef8-6667ec942ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_train = \"helge_TRAIN_dataset_window{}_sincostime_ver{}.nc\".format(window,ver)\n",
    "\n",
    "import xarray as xr\n",
    "xr_dataset = xr.open_dataset(fn_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6450db-0504-41b5-adc2-ae6a496070c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1029a4d4-a69e-4486-83f3-86d9740384f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_dataset.dims['input_dim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455cba54-ca6e-42c2-ba02-4b84543a54be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "coords = np.arange(xr_dataset.dims['input_dim'])\n",
    "\n",
    "xr_mean = xr.DataArray(xr_dataset.mean(dim='sample_dim').samples, \n",
    "             coords=[coords], \n",
    "             dims=[\"features\"],\n",
    "             name=\"mean\",\n",
    "             attrs={\n",
    "                 \"features\":'[3*window^2+month_sin+month_cos+lat+lon+y]',\n",
    "                  }) \n",
    "\n",
    "xr_std = xr.DataArray(xr_dataset.std(dim='sample_dim').samples, \n",
    "             coords=[coords], \n",
    "             dims=[\"features\"],\n",
    "             name=\"stddev\",\n",
    "             attrs={\n",
    "                 \"features\":'[3*window^2+month_sin+month_cos+lat+lon+y]',\n",
    "                  }) \n",
    "\n",
    "xr_dataset_mean_std = xr.merge( [xr_mean, xr_std], compat='override', combine_attrs='override', )\n",
    "print(xr_dataset_mean_std)\n",
    "\n",
    "\n",
    "fn = \"helge_MEAN_STDDEV_dataset_window{}_sincostime_ver{}.nc\".format(window,ver)\n",
    "xr_dataset_mean_std.to_netcdf(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2c7bb0-ad60-49e2-a38a-6c6f2ac4f924",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb46752b-db97-4d5a-b26c-db0d287e4cf7",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef2183f-ccb4-4969-8c20-4d0b1391d034",
   "metadata": {},
   "outputs": [],
   "source": [
    "#regr = RandomForestRegressor(max_depth=4, n_jobs=-1, max_samples=0.1)\n",
    "regr = LinearRegression()\n",
    "regr.fit(train_predictors, train_predictands)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae5d9f7-849d-45a8-a928-2f5d98a51524",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b10abdc-d33f-4301-ab2f-9b50711b7d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = regr.predict(test_predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5681d9c9-19eb-4589-bc3f-e29612f9b371",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8693e68-0bb7-4611-b1aa-66d5758669f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(pred, test_predictands)\n",
    "print('MSE:', mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90088c84-2edd-4c48-a4b0-df8abe1441c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape prediction to initial shape\n",
    "pred = pred.reshape(orig_shape_ytest)\n",
    "test_predictands = test_predictands.reshape(orig_shape_ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84cc787-4ad6-473b-b2f0-ea72b3a9ca90",
   "metadata": {},
   "outputs": [],
   "source": [
    "time = np.random.randint(pred.shape[0])\n",
    "plt.figure(figsize=(30,6))\n",
    "plt.subplot(1,3,1)\n",
    "plt.title('Prediction')\n",
    "plt.imshow(pred[time,:,:])\n",
    "plt.colorbar()\n",
    "plt.subplot(1,3,2)\n",
    "plt.title('Truth')\n",
    "plt.imshow(test_predictands[time,:,:])\n",
    "plt.colorbar()\n",
    "plt.subplot(1,3,3)\n",
    "plt.title('Error')\n",
    "plt.imshow(test_predictands[time,:,:]-pred[time,:,:])\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076d46ff-66ef-45b5-b150-0b1f712e0fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot spi time series at random location\n",
    "lat = np.random.randint(pred.shape[1])\n",
    "lon = np.random.randint(pred.shape[2])\n",
    "k = np.random.randint(pred.shape[0]-100)\n",
    "plt.plot(pred[k:k+100,lat,lon], label='Pred')\n",
    "plt.plot(test_predictands[k:k+100,lat,lon], label='Truth')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dc4031-0250-4a77-8573-30db43eba507",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
