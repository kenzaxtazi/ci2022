{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8592b10-f936-4bc2-9250-6131c8802306",
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4 as nc\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a73128-883f-471f-a4f8-aedeff307f80",
   "metadata": {},
   "source": [
    "#download\n",
    "!curl https://zenodo.org/record/6532501/files/CESM_EA_SPI.nc?download=1 --output CESM_EA_SPI.nc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177ab34f-0ff7-442e-a896-9f8477f0ca83",
   "metadata": {},
   "source": [
    "# Run Main file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178c4365-279a-4b83-a847-9e070a24e6e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%run train_siren.py\n",
    "# --fast_dev_run 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf8b527-f25b-4ae8-b54f-890e16dbc764",
   "metadata": {},
   "source": [
    "## RAW DATA SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c29276a-8218-4149-962f-ef230d431dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'CESM_EA_SPI.nc'\n",
    "ds = xr.open_dataset(file_name)\n",
    "spi = ds['spi']\n",
    "ds.close()\n",
    "spi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed3073d-1cff-43ae-be48-dc8554c15c3d",
   "metadata": {},
   "source": [
    "# Experiment month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dab5e7f-6182-426c-9606-b4085278ef4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_month = pd.DataFrame(spi[\"time\"].to_series().values, columns=['time'])\n",
    "month = dim_month['time'].apply(lambda x: datetime.strptime(str(x), '%Y-%m-%dT%H:%M:%S').month).values\n",
    "fract = (month-1)/12*np.pi*2\n",
    "month_sin = np.sin(fract)\n",
    "month_cos = np.cos(fract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dda37d-2e65-4e27-bb24-84a089411fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2e41d5-ea31-4bc8-9b6e-ca66559cd681",
   "metadata": {},
   "outputs": [],
   "source": [
    "month = 12\n",
    "tmp=(month-1)/12*np.pi*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c409ea-20c2-4a9f-808e-be4fc5ece809",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sin(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e5e0e1-77ad-4e39-9795-185c4f9e16a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.cos(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17c1dd3-4c96-409a-bb82-e5fcebc342b0",
   "metadata": {},
   "source": [
    "# Experiment Padding Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d52bc7-2d83-47d8-aa29-ff8812049c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = train_predictands[0,:,:]\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a23a31-9b15-451c-ab82-e3ac78de2128",
   "metadata": {},
   "outputs": [],
   "source": [
    "window=1\n",
    "img_pad = np.pad(img, pad_width=window, mode='symmetric')\n",
    "img_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b39671-d58e-4fb9-bd56-a7278cb3c068",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.reshape(np.shape(X)[0]*np.shape(X)[1]*np.shape(X)[2], np.shape(X)[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb8c153-7931-4037-bef3-98b703ddf723",
   "metadata": {},
   "outputs": [],
   "source": [
    "window=5\n",
    "\n",
    "data_x = []\n",
    "data_y = []\n",
    "\n",
    "for time_idx in range(num_samples):\n",
    "    img_y = y[time_idx,:,:]\n",
    "    img_pad_y = np.pad(img_y, pad_width=window, mode='symmetric')\n",
    "    \n",
    "    img_x = X[time_idx,:,:,:]\n",
    "    img_pad_x[:,:,0] = np.pad(img_pad_y[:,:,0], pad_width=window, mode='symmetric')\n",
    "    img_pad_x[:,:,1] = np.pad(img_pad_y[:,:,1], pad_width=window, mode='symmetric')\n",
    "    img_pad_x[:,:,2] = np.pad(img_pad_y[:,:,2], pad_width=window, mode='symmetric')\n",
    "    \n",
    "    for lat in range(window, 13):\n",
    "        for lon in range(window, 20):\n",
    "            # y\n",
    "            sample_y = img_pad_y[lat:lat+window,lon:lon+window]\n",
    "            sample_y = sample_y.reshape(np.shape(sample_y)[0]*np.shape(sample_y)[1])\n",
    "            data_y.append(sample_y)\n",
    "            \n",
    "            # x\n",
    "            sample = img_pad_x[lat:lat+window,lon:lon+window,:]\n",
    "            sample = sample.reshape(np.shape(sample)[0]*np.shape(sample)[1]*np.shape(sample)[2])\n",
    "            data_x.append(sample)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77dee9a-adc9-4540-981f-c8ef711ee6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "spi[dict(time=0, lat=slice(None, 2), lon=slice(None, 2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8719cc-ac80-4bf7-8133-9664e0c366ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "spi.sel(lat=slice(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0187129-02cc-4f16-bed0-8d4f46e3a37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot spatial spi distribution for random time\n",
    "time = np.random.randint(spi.shape[0])\n",
    "spi2d = spi.isel(time=time)\n",
    "spi2d.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711a36f4-8f42-464b-8d59-3286adcf2305",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot spi time series at random location\n",
    "lat = np.random.randint(spi.shape[1])\n",
    "lon = np.random.randint(spi.shape[2])\n",
    "k = np.random.randint(spi.shape[0]-1000)\n",
    "plt.plot(spi[k:k+1000,lat,lon])\n",
    "plt.ylabel('SPI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2071b52-f150-4f02-9c41-a717bb9da816",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot overall spi distribution\n",
    "plt.hist(np.array(spi).flatten(), bins=100)\n",
    "plt.title('SPI distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd12f5c9-4034-4f7a-87f5-d31c03330283",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97e07ff5-aa8a-4460-a41e-c2c1273b11fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def helge_assemble_predictors_predictands(start_date, end_date, lead_time, dataset, num_input_time_steps, window=5):\n",
    "    '''\n",
    "    Args\n",
    "    ----\n",
    "    start_date (str): The start date for extraction. Important, put the trailing 0 at the beginning of year for dates before 1000 (e.g., '0400')\n",
    "    end_date (str): The end date for extraction\n",
    "    lead_time (int): The number of months between the predictor/predictand\n",
    "    dataset (str): Either 'CESM' or 'ECMWF'\n",
    "    num_input_time_steps (int): The number of time steps to use for each predictor samples\n",
    "    '''    \n",
    "    file_name = {'CESM': 'CESM_EA_SPI.nc', 'ECMWF': 'ECMWF_EA_SPI.nc'}[dataset]\n",
    "    ds = xr.open_dataset(file_name)\n",
    "    spi = ds['spi'].sel(time=slice(start_date,end_date))\n",
    "    num_samples=spi.shape[0] \n",
    "    #Stack and remove nans\n",
    "    spi = np.stack([spi.values[n-num_input_time_steps:n] for n in range(num_input_time_steps, num_samples+1)])\n",
    "    num_samples = spi.shape[0]\n",
    "    spi[np.isnan(spi)] = 0\n",
    "    #make sure we have floats in there\n",
    "    X = spi.astype(np.float32)\n",
    "    # select Y\n",
    "    if dataset == 'ECMWF':\n",
    "        start_date_plus_lead = pd.to_datetime(start_date) + pd.DateOffset(months=lead_time+num_input_time_steps-1)\n",
    "        end_date_plus_lead = pd.to_datetime(end_date) + pd.DateOffset(months=lead_time)\n",
    "    elif dataset == 'CESM':\n",
    "        t_start=datetime.datetime(int(start_date.split('-')[0]),int(start_date.split('-')[1]),int(start_date.split('-')[2]))\n",
    "        t_end=datetime.datetime(int(end_date.split('-')[0]),int(end_date.split('-')[1]),int(end_date.split('-')[2]))\n",
    "        start_date_plus_lead = t_start + relativedelta(months=lead_time+num_input_time_steps-1)\n",
    "        end_date_plus_lead = t_end + relativedelta(months=lead_time)\n",
    "        if len(str(start_date_plus_lead.year))<4:\n",
    "            start_date_plus_lead = '0'+start_date_plus_lead.strftime('%Y-%m-%d')\n",
    "        elif len(str(start_date_plus_lead.year))==4:\n",
    "            start_date_plus_lead = start_date_plus_lead.strftime('%Y-%m-%d')\n",
    "        if len(str(end_date_plus_lead.year))<4:\n",
    "            end_date_plus_lead = '0'+end_date_plus_lead.strftime('%Y-%m-%d')\n",
    "        elif len(str(end_date_plus_lead.year))==4:\n",
    "            end_date_plus_lead = end_date_plus_lead.strftime('%Y-%m-%d')\n",
    "    subsetted_ds = ds['spi'].sel(time=slice(start_date_plus_lead, end_date_plus_lead))\n",
    "    y = subsetted_ds.values.astype(np.float32)\n",
    "    y[np.isnan(y)] = 0\n",
    "    # add month feature\n",
    "    month = pd.DataFrame(subsetted_ds[\"time\"].to_series().values, columns=['time'])\n",
    "    month = month['time'].apply(lambda x: datetime.datetime.strptime(str(x), '%Y-%m-%dT%H:%M:%S').month).values\n",
    "    fract = (month-1)/12*np.pi*2\n",
    "    month_sin = np.sin(fract)\n",
    "    month_cos = np.cos(fract)       \n",
    "    ds.close()\n",
    "    X = np.moveaxis(X, 1,3)\n",
    "    orig_shape_X = X.shape\n",
    "    orig_shape_y = y.shape\n",
    "    #y = y.reshape(np.shape(y)[0]*np.shape(y)[1]*np.shape(y)[2])\n",
    "    #X = X.reshape(np.shape(X)[0]*np.shape(X)[1]*np.shape(X)[2], np.shape(X)[3])\n",
    "\n",
    "    data_set = []\n",
    "    halfwindow = int(window/2)\n",
    "\n",
    "    for time_idx in range(num_samples):\n",
    "        img_y = y[time_idx,:,:]\n",
    "        img_pad_y = np.pad(img_y, pad_width=window, mode='symmetric')\n",
    "        \n",
    "        img_x = X[time_idx,:,:,:]\n",
    "        img_pad_x = np.ndarray((img_pad_y.shape[0], img_pad_y.shape[1], 3))\n",
    "        img_pad_x[:,:,0] = np.pad(img_x[:,:,0], pad_width=window, mode='symmetric')\n",
    "        img_pad_x[:,:,1] = np.pad(img_x[:,:,1], pad_width=window, mode='symmetric')\n",
    "        img_pad_x[:,:,2] = np.pad(img_x[:,:,2], pad_width=window, mode='symmetric')\n",
    "        for lat in range(window, 13+window):\n",
    "            for lon in range(window, 20+window):\n",
    "\n",
    "                # x\n",
    "                sample = img_pad_x[lat-halfwindow:lat+halfwindow+1,lon-halfwindow:lon+halfwindow+1,:]\n",
    "                sample = sample.reshape(np.shape(sample)[0]*np.shape(sample)[1]*np.shape(sample)[2])\n",
    "                sample = np.append(sample, month_sin[time_idx])\n",
    "                sample = np.append(sample, month_cos[time_idx])\n",
    "                sample = np.append(sample, lat)\n",
    "                sample = np.append(sample, lon)\n",
    "                \n",
    "                # y\n",
    "                sample_y = img_pad_y[lat,lon]\n",
    "                #sample_y = img_pad_y[lat:lat+window,lon:lon+window]\n",
    "                #sample_y = sample_y.reshape(np.shape(sample_y)[0]*np.shape(sample_y)[1])\n",
    "                #data_y.append(sample_y)                \n",
    "                sample = np.append(sample, sample_y)\n",
    "                data_set.append(sample)\n",
    "        #break\n",
    "    return np.array(data_set)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f655e89-fb1d-4d99-8ffd-600f435af5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_input_time_steps = 3 \n",
    "lead_time = 3\n",
    "window = 5\n",
    "\n",
    "climate_model = 'CESM'\n",
    "\n",
    "all_start_date = '0400-01-01'\n",
    "all_end_date = '2021-12-31'\n",
    "\n",
    "#train_start_date = '0400-01-01'\n",
    "#train_end_date = '1800-12-31'\n",
    "\n",
    "#test_start_date = '1801-01-01'\n",
    "#test_end_date = '1978-12-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4d08e13d-abe7-4002-b63a-ecf778cda361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5060120, 80)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set = helge_assemble_predictors_predictands(all_start_date, all_end_date, lead_time, climate_model, num_input_time_steps, window)\n",
    "data_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88ba132-fc07-41fa-abf3-8c934e24f630",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9b565f-c19d-46cb-8372-f284855dae2f",
   "metadata": {},
   "source": [
    "# Store new dataset as netcdf files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "194f14a6-b8b9-45a2-a3b2-c71bd8876214",
   "metadata": {},
   "outputs": [
    {
     "ename": "DistributionNotFound",
     "evalue": "The 'wandb' distribution was not found and is required by the application",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDistributionNotFound\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[0;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m seed \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     25\u001b[0m train_fract \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.8\u001b[39m\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpl\u001b[39;00m\n\u001b[1;32m     27\u001b[0m pl\u001b[38;5;241m.\u001b[39mseed_everything(seed)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# split in train and test data\u001b[39;00m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/pytorch_lightning/__init__.py:30\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m     _logger\u001b[38;5;241m.\u001b[39maddHandler(logging\u001b[38;5;241m.\u001b[39mStreamHandler())\n\u001b[1;32m     28\u001b[0m     _logger\u001b[38;5;241m.\u001b[39mpropagate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Callback  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LightningDataModule, LightningModule  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Trainer  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/pytorch_lightning/callbacks/__init__.py:14\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright The PyTorch Lightning team.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Callback\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdevice_stats_monitor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DeviceStatsMonitor\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mearly_stopping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EarlyStopping\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/pytorch_lightning/callbacks/base.py:25\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Optimizer\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpl\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutilities\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m STEP_OUTPUT\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCallback\u001b[39;00m:\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03m    Abstract base class used to build new callbacks.\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03m    Subclass this class and override any of the relevant hooks\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/pytorch_lightning/utilities/__init__.py:18\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03m\"\"\"General utilities.\"\"\"\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutilities\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply_func\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m move_data_to_device  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutilities\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AllGatherGrad  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutilities\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menums\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     _AcceleratorType,\n\u001b[1;32m     22\u001b[0m     _StrategyType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m     ModelSummaryMode,\n\u001b[1;32m     28\u001b[0m )\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/pytorch_lightning/utilities/apply_func.py:29\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutilities\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MisconfigurationException\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutilities\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimports\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _compare_version, _TORCHTEXT_LEGACY\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutilities\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwarnings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m rank_zero_deprecation\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _TORCHTEXT_LEGACY:\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/pytorch_lightning/utilities/imports.py:124\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    122\u001b[0m _TORCHVISION_AVAILABLE \u001b[38;5;241m=\u001b[39m _package_available(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorchvision\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    123\u001b[0m _WANDB_AVAILABLE \u001b[38;5;241m=\u001b[39m _package_available(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwandb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 124\u001b[0m _WANDB_GREATER_EQUAL_0_10_22 \u001b[38;5;241m=\u001b[39m _WANDB_AVAILABLE \u001b[38;5;129;01mand\u001b[39;00m \u001b[43m_compare_version\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwandb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mge\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m0.10.22\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m _WANDB_GREATER_EQUAL_0_12_10 \u001b[38;5;241m=\u001b[39m _WANDB_AVAILABLE \u001b[38;5;129;01mand\u001b[39;00m _compare_version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwandb\u001b[39m\u001b[38;5;124m\"\u001b[39m, operator\u001b[38;5;241m.\u001b[39mge, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.12.10\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    126\u001b[0m _XLA_AVAILABLE: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m _package_available(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch_xla\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/pytorch_lightning/utilities/imports.py:79\u001b[0m, in \u001b[0;36m_compare_version\u001b[0;34m(package, op, version, use_base_version)\u001b[0m\n\u001b[1;32m     76\u001b[0m         pkg_version \u001b[38;5;241m=\u001b[39m Version(pkg\u001b[38;5;241m.\u001b[39m__version__)\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;66;03m# try pkg_resources to infer version\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m         pkg_version \u001b[38;5;241m=\u001b[39m Version(\u001b[43mpkg_resources\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_distribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mversion)\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;66;03m# this is mocked by Sphinx, so it should return True to generate all summaries\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/pkg_resources/__init__.py:471\u001b[0m, in \u001b[0;36mget_distribution\u001b[0;34m(dist)\u001b[0m\n\u001b[1;32m    469\u001b[0m     dist \u001b[38;5;241m=\u001b[39m Requirement\u001b[38;5;241m.\u001b[39mparse(dist)\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dist, Requirement):\n\u001b[0;32m--> 471\u001b[0m     dist \u001b[38;5;241m=\u001b[39m \u001b[43mget_provider\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdist\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dist, Distribution):\n\u001b[1;32m    473\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected string, Requirement, or Distribution\u001b[39m\u001b[38;5;124m\"\u001b[39m, dist)\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/pkg_resources/__init__.py:347\u001b[0m, in \u001b[0;36mget_provider\u001b[0;34m(moduleOrReq)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;124;03m\"\"\"Return an IResourceProvider for the named module or requirement\"\"\"\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(moduleOrReq, Requirement):\n\u001b[0;32m--> 347\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m working_set\u001b[38;5;241m.\u001b[39mfind(moduleOrReq) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mrequire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmoduleOrReq\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    349\u001b[0m     module \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mmodules[moduleOrReq]\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/pkg_resources/__init__.py:891\u001b[0m, in \u001b[0;36mWorkingSet.require\u001b[0;34m(self, *requirements)\u001b[0m\n\u001b[1;32m    882\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequire\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mrequirements):\n\u001b[1;32m    883\u001b[0m     \u001b[38;5;124;03m\"\"\"Ensure that distributions matching `requirements` are activated\u001b[39;00m\n\u001b[1;32m    884\u001b[0m \n\u001b[1;32m    885\u001b[0m \u001b[38;5;124;03m    `requirements` must be a string or a (possibly-nested) sequence\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    889\u001b[0m \u001b[38;5;124;03m    included, even if they were already activated in this working set.\u001b[39;00m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 891\u001b[0m     needed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparse_requirements\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequirements\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    893\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m dist \u001b[38;5;129;01min\u001b[39;00m needed:\n\u001b[1;32m    894\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd(dist)\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/pkg_resources/__init__.py:777\u001b[0m, in \u001b[0;36mWorkingSet.resolve\u001b[0;34m(self, requirements, env, installer, replace_conflicting, extras)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m dist \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    776\u001b[0m             requirers \u001b[38;5;241m=\u001b[39m required_by\u001b[38;5;241m.\u001b[39mget(req, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 777\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m DistributionNotFound(req, requirers)\n\u001b[1;32m    778\u001b[0m     to_activate\u001b[38;5;241m.\u001b[39mappend(dist)\n\u001b[1;32m    779\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dist \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m req:\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;66;03m# Oops, the \"best\" so far conflicts with a dependency\u001b[39;00m\n",
      "\u001b[0;31mDistributionNotFound\u001b[0m: The 'wandb' distribution was not found and is required by the application"
     ]
    }
   ],
   "source": [
    "def store_data(data_set, fn: str)->None:\n",
    "    import xarray as xr\n",
    "    sample_ticks = np.arange(data_set.shape[0])\n",
    "    input_ticks = np.arange(data_set.shape[1])\n",
    "\n",
    "    xr_drought = xr.DataArray(data_set, \n",
    "                 coords=[sample_ticks, input_ticks], \n",
    "                 dims=[\"sample_dim\", \"input_dim\"],\n",
    "                 name=\"samples\",\n",
    "                 attrs={\"begin\":all_start_date,\n",
    "                        \"end\":all_end_date,\n",
    "                        \"climate_model\":climate_model, \n",
    "                        \"num_input_time_steps\":num_input_time_steps,\n",
    "                        \"lead_time\":lead_time,\n",
    "                        \"unit\":\"Standard Precipitation Index (SPI)\",\n",
    "                      })\n",
    "\n",
    "    xr_dataset = xr.merge( [xr_drought], compat='override' )\n",
    "    print(xr_dataset)\n",
    "\n",
    "    xr_dataset.to_netcdf(fn)\n",
    "    \n",
    "# set seed\n",
    "seed = 1\n",
    "train_fract = 0.8\n",
    "import pytorch_lightning as pl\n",
    "pl.seed_everything(seed)\n",
    "\n",
    "# split in train and test data\n",
    "import numpy as np\n",
    "rng = np.random.default_rng(seed)\n",
    "msk = rng.random(X.shape[0]) < 0.8\n",
    "data_set_train = data_set[msk,:]\n",
    "data_set_test = data_set[~msk,:]\n",
    "\n",
    "ver = 1\n",
    "fn = \"helge_TRAIN_dataset_window{}_sincostime_ver{}.nc\".format(window,ver)\n",
    "store_data(data_set_train, fn)\n",
    "\n",
    "fn = \"helge_TEST_dataset_sincostime_ver{}.nc\".format(ver)\n",
    "store_data(data_set_test, fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa12fbaa-c485-4323-bb2d-cd7f9f02c3e0",
   "metadata": {},
   "source": [
    "# Store mean std dev of training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9d13f9-b626-46b9-aef8-6667ec942ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_train = \"helge_TRAIN_dataset_window{}_sincostime_ver{}.nc\".format(window,ver)\n",
    "\n",
    "import xarray as xr\n",
    "xr_dataset = xr.open_dataset(fn_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6450db-0504-41b5-adc2-ae6a496070c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1029a4d4-a69e-4486-83f3-86d9740384f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_dataset.dims['input_dim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455cba54-ca6e-42c2-ba02-4b84543a54be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "coords = np.arange(xr_dataset.dims['input_dim'])\n",
    "\n",
    "xr_mean = xr.DataArray(xr_dataset.mean(dim='sample_dim').samples, \n",
    "             coords=[coords], \n",
    "             dims=[\"features\"],\n",
    "             name=\"mean\",\n",
    "             attrs={\n",
    "                 \"features\":'[3*window^2+month_sin+month_cos+lat+lon+y]',\n",
    "                  }) \n",
    "\n",
    "xr_std = xr.DataArray(xr_dataset.std(dim='sample_dim').samples, \n",
    "             coords=[coords], \n",
    "             dims=[\"features\"],\n",
    "             name=\"stddev\",\n",
    "             attrs={\n",
    "                 \"features\":'[3*window^2+month_sin+month_cos+lat+lon+y]',\n",
    "                  }) \n",
    "\n",
    "xr_dataset_mean_std = xr.merge( [xr_mean, xr_std], compat='override', combine_attrs='override', )\n",
    "print(xr_dataset_mean_std)\n",
    "\n",
    "\n",
    "fn = \"helge_MEAN_STDDEV_dataset_window{}_sincostime.nc\".format(window)\n",
    "xr_dataset_mean_std.to_netcdf(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2c7bb0-ad60-49e2-a38a-6c6f2ac4f924",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb46752b-db97-4d5a-b26c-db0d287e4cf7",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef2183f-ccb4-4969-8c20-4d0b1391d034",
   "metadata": {},
   "outputs": [],
   "source": [
    "#regr = RandomForestRegressor(max_depth=4, n_jobs=-1, max_samples=0.1)\n",
    "regr = LinearRegression()\n",
    "regr.fit(train_predictors, train_predictands)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae5d9f7-849d-45a8-a928-2f5d98a51524",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b10abdc-d33f-4301-ab2f-9b50711b7d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = regr.predict(test_predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5681d9c9-19eb-4589-bc3f-e29612f9b371",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8693e68-0bb7-4611-b1aa-66d5758669f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(pred, test_predictands)\n",
    "print('MSE:', mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90088c84-2edd-4c48-a4b0-df8abe1441c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape prediction to initial shape\n",
    "pred = pred.reshape(orig_shape_ytest)\n",
    "test_predictands = test_predictands.reshape(orig_shape_ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84cc787-4ad6-473b-b2f0-ea72b3a9ca90",
   "metadata": {},
   "outputs": [],
   "source": [
    "time = np.random.randint(pred.shape[0])\n",
    "plt.figure(figsize=(30,6))\n",
    "plt.subplot(1,3,1)\n",
    "plt.title('Prediction')\n",
    "plt.imshow(pred[time,:,:])\n",
    "plt.colorbar()\n",
    "plt.subplot(1,3,2)\n",
    "plt.title('Truth')\n",
    "plt.imshow(test_predictands[time,:,:])\n",
    "plt.colorbar()\n",
    "plt.subplot(1,3,3)\n",
    "plt.title('Error')\n",
    "plt.imshow(test_predictands[time,:,:]-pred[time,:,:])\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076d46ff-66ef-45b5-b150-0b1f712e0fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot spi time series at random location\n",
    "lat = np.random.randint(pred.shape[1])\n",
    "lon = np.random.randint(pred.shape[2])\n",
    "k = np.random.randint(pred.shape[0]-100)\n",
    "plt.plot(pred[k:k+100,lat,lon], label='Pred')\n",
    "plt.plot(test_predictands[k:k+100,lat,lon], label='Truth')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dc4031-0250-4a77-8573-30db43eba507",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
